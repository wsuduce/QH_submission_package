{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook: mcmc_k_equals_c_beta_over_alpha.ipynb\n",
        "\n",
        "**Objective:** Test the relationship k = c * (β/α) using MCMC on MIDIS observational data, where k is the cosmological scaling parameter and β/α is the laboratory-measured ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import emcee\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# parameters (papermill-friendly)\n",
        "DATA_CSV = \"../data/midis_f560w_masslim.csv\"\n",
        "\n",
        "# Load MIDIS data from SST source\n",
        "midis_data = pd.read_csv(DATA_CSV)\n",
        "print(\"MIDIS observational data:\")\n",
        "print(midis_data)\n",
        "\n",
        "# Extract data\n",
        "z = midis_data['z'].values\n",
        "g = midis_data['g'].values\n",
        "g_err = midis_data['g_err'].values\n",
        "\n",
        "# Define log-likelihood\n",
        "def log_likelihood(params, z, g, g_err):\n",
        "    ln_g0, k = params\n",
        "    model = ln_g0 - k * z\n",
        "    ln_g = np.log(g)\n",
        "    sigma2 = (g_err / g)**2\n",
        "    return -0.5 * np.sum((ln_g - model)**2 / sigma2 + np.log(2 * np.pi * sigma2))\n",
        "\n",
        "# Initial guess from least squares\n",
        "X = np.column_stack([np.ones_like(z), -z])\n",
        "ln_g = np.log(g)\n",
        "weights = 1.0 / (g_err / g)**2\n",
        "W = np.diag(weights)\n",
        "beta = np.linalg.inv(X.T @ W @ X) @ (X.T @ W @ ln_g)\n",
        "ln_g0_init, k_init = beta\n",
        "\n",
        "print(f\"Initial estimates: ln_g0 = {ln_g0_init:.3f}, k = {k_init:.3f}\")\n",
        "\n",
        "# MCMC sampling\n",
        "nwalkers, ndim = 32, 2\n",
        "p0 = [ln_g0_init, k_init] + 0.1 * np.random.randn(nwalkers, ndim)\n",
        "\n",
        "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_likelihood, args=(z, g, g_err))\n",
        "sampler.run_mcmc(p0, 1000, progress=True)\n",
        "\n",
        "# Results\n",
        "samples = sampler.get_chain(discard=200, flat=True)\n",
        "ln_g0_mcmc, k_mcmc = np.mean(samples, axis=0)\n",
        "ln_g0_err, k_err = np.std(samples, axis=0)\n",
        "\n",
        "print(f\"\\nMCMC Results:\")\n",
        "print(f\"ln_g0 = {ln_g0_mcmc:.3f} ± {ln_g0_err:.3f}\")\n",
        "print(f\"k = {k_mcmc:.3f} ± {k_err:.3f}\")\n",
        "\n",
        "# Compare with theoretical prediction\n",
        "beta_over_alpha = 0.0503\n",
        "k_theoretical = beta_over_alpha  # QH framework prediction\n",
        "\n",
        "print(f\"\\nTheoretical k = {k_theoretical:.3f} (from β/α)\")\n",
        "agreement_sigma = abs(k_mcmc - k_theoretical) / k_err\n",
        "print(f\"Agreement: {agreement_sigma:.2f}σ\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}